{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polymarket Price Prediction - Interactive Notebook\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for predicting Polymarket prices.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collect_polymarket_data import PolymarketDataCollector\n",
    "from feature_engineering import PolymarketFeatureEngineering\n",
    "from train_model import PolymarketPredictor\n",
    "from predict_markets import PolymarketLivePredictor\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Fetch historical data from Polymarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize collector\n",
    "collector = PolymarketDataCollector()\n",
    "\n",
    "# Get active markets\n",
    "markets = collector.get_active_markets(limit=20)\n",
    "\n",
    "print(f\"Found {len(markets)} markets\\n\")\n",
    "print(\"Sample markets:\")\n",
    "for i, market in enumerate(markets[:5]):\n",
    "    print(f\"{i+1}. {market.get('question', 'N/A')[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect detailed data for markets\n",
    "datasets = collector.collect_multiple_markets(num_markets=10, resample_freq='1H')\n",
    "\n",
    "print(f\"Collected {len(datasets)} market datasets\")\n",
    "\n",
    "# Save the data\n",
    "if datasets:\n",
    "    collector.save_datasets(datasets)\n",
    "    print(\"✓ Data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore data\n",
    "with open('polymarket_data/polymarket_training_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Show summary statistics\n",
    "summary_df = pd.read_csv('polymarket_data/polymarket_training_data_summary.csv')\n",
    "display(summary_df.head())\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Total markets: {len(data)}\")\n",
    "print(f\"Average trades per market: {summary_df['total_trades'].mean():.0f}\")\n",
    "print(f\"Average volume: ${summary_df['total_volume'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample market's price history\n",
    "sample_market = data[0]\n",
    "timeseries = pd.DataFrame(sample_market['timeseries'])\n",
    "\n",
    "if not timeseries.empty and 'timestamp' in timeseries and 'close' in timeseries:\n",
    "    timeseries['timestamp'] = pd.to_datetime(timeseries['timestamp'])\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(timeseries['timestamp'], timeseries['close'], linewidth=2)\n",
    "    plt.title(f\"Price History: {sample_market['market_info']['question'][:70]}\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = PolymarketFeatureEngineering()\n",
    "\n",
    "# Load datasets\n",
    "datasets = engineer.load_data('polymarket_data/polymarket_training_data.json')\n",
    "\n",
    "# Prepare training data\n",
    "training_df = engineer.prepare_training_data(datasets, prediction_horizon=6)\n",
    "\n",
    "print(f\"Training dataset shape: {training_df.shape}\")\n",
    "print(f\"Features: {len(engineer.get_feature_columns(training_df))}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(training_df['target_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore feature distributions\n",
    "feature_cols = engineer.get_feature_columns(training_df)\n",
    "\n",
    "# Show first few features\n",
    "print(\"Sample features:\")\n",
    "for col in feature_cols[:10]:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Display feature statistics\n",
    "display(training_df[feature_cols[:10]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature correlations\n",
    "selected_features = ['momentum_1h', 'momentum_6h', 'volatility_6h', \n",
    "                    'volume_change', 'rsi', 'target_binary']\n",
    "available_features = [f for f in selected_features if f in training_df.columns]\n",
    "\n",
    "if len(available_features) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(training_df[available_features].corr(), \n",
    "                annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlations')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = PolymarketPredictor()\n",
    "\n",
    "# Prepare features and target\n",
    "X, y = predictor.prepare_features_and_target(training_df)\n",
    "\n",
    "# Split data\n",
    "data_splits = predictor.split_data(X, y, test_size=0.2, val_size=0.1)\n",
    "\n",
    "# Scale features\n",
    "data_splits = predictor.scale_features(data_splits)\n",
    "\n",
    "print(\"✓ Data prepared for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare models\n",
    "results = predictor.compare_models(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Val Accuracy': [],\n",
    "    'Val F1': [],\n",
    "    'Val ROC AUC': []\n",
    "})\n",
    "\n",
    "for name, result in results.items():\n",
    "    comparison_df = pd.concat([comparison_df, pd.DataFrame([{\n",
    "        'Model': name,\n",
    "        'Train Accuracy': result['train_metrics']['accuracy'],\n",
    "        'Val Accuracy': result['val_metrics']['accuracy'],\n",
    "        'Val F1': result['val_metrics']['f1'],\n",
    "        'Val ROC AUC': result['val_metrics']['roc_auc']\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics = ['Val Accuracy', 'Val F1', 'Val ROC AUC']\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[i].bar(comparison_df['Model'], comparison_df[metric])\n",
    "    axes[i].set_title(metric)\n",
    "    axes[i].set_ylim([0, 1])\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and save best model\n",
    "best_model_name, best_model = predictor.select_best_model(results)\n",
    "\n",
    "# Final test evaluation\n",
    "test_metrics = predictor.evaluate_model(\n",
    "    best_model,\n",
    "    data_splits['X_test_scaled'],\n",
    "    data_splits['y_test'],\n",
    "    \"Test\"\n",
    ")\n",
    "\n",
    "# Save model\n",
    "predictor.model = best_model\n",
    "predictor.save_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance (if Random Forest)\n",
    "if best_model_name == 'Random Forest' and predictor.feature_importance is not None:\n",
    "    top_n = 20\n",
    "    top_features = predictor.feature_importance.head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=top_features, x='importance', y='feature')\n",
    "    plt.title(f'Top {top_n} Most Important Features')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    display(top_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Live Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictor for live markets\n",
    "live_predictor = PolymarketLivePredictor()\n",
    "\n",
    "# Get top markets\n",
    "condition_ids = live_predictor.get_top_markets_to_predict(limit=5)\n",
    "\n",
    "print(f\"Found {len(condition_ids)} markets for prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if condition_ids:\n",
    "    predictions = live_predictor.predict_multiple_markets(condition_ids)\n",
    "    \n",
    "    # Display predictions\n",
    "    pred_df = pd.DataFrame([{\n",
    "        'Question': p['question'][:50] + '...',\n",
    "        'Prediction': p['prediction_label'],\n",
    "        'Probability': f\"{p['probability']:.2%}\",\n",
    "        'Confidence': p['confidence'],\n",
    "        'Current Price': p['current_price']\n",
    "    } for p in predictions])\n",
    "    \n",
    "    display(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction confidence distribution\n",
    "if predictions:\n",
    "    confidences = [p['probability'] for p in predictions]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(confidences, bins=10, edgecolor='black')\n",
    "    plt.axvline(x=0.5, color='red', linestyle='--', label='Neutral (50%)')\n",
    "    plt.xlabel('Prediction Probability')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Prediction Confidence')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Insights & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive summary\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Accuracy:  {test_metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.2%}\")\n",
    "print(f\"  Recall:    {test_metrics['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "print(f\"  ROC AUC:   {test_metrics['roc_auc']:.4f}\")\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  Markets:   {len(datasets)}\")\n",
    "print(f\"  Samples:   {len(training_df)}\")\n",
    "print(f\"  Features:  {len(predictor.feature_names)}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
